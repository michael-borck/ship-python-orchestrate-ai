{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Case Study: From Notebook to Package with nbdev {#sec-notebook-case-study}\n",
        "\n",
        "::: {.callout-note}\n",
        "## Chapter Overview\n",
        "This case study parallels @sec-case-study (SimpleBot), but follows a notebook-first workflow. We'll build TextKit‚Äîa text analysis library‚Äîentirely in Jupyter notebooks, then ship it as a published Python package using nbdev.\n",
        ":::\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "TextKit is a lightweight text analysis library that provides simple utilities for analyzing text. Key features include:\n",
        "\n",
        "- Word and character statistics\n",
        "- Readability scoring (Flesch-Kincaid, etc.)\n",
        "- Basic sentiment indicators\n",
        "- Text cleaning utilities\n",
        "\n",
        "This project is ideal for our notebook case study because:\n",
        "\n",
        "- **Natural notebook fit**: Text analysis involves exploration and visualization\n",
        "- **Keeps the theme**: Complements SimpleBot's chatbot focus (analyzing what bots produce)\n",
        "- **Real utility**: Functions you'd actually use in data analysis\n",
        "- **Right size**: Small enough to complete, complex enough to demonstrate the workflow\n",
        "\n",
        "By the end of this chapter, you'll have a package published to PyPI‚Äîbuilt entirely from notebooks.\n",
        "\n",
        "## Why nbdev for This Project?\n",
        "\n",
        "In @sec-notebooks, we introduced nbdev as a way to develop libraries from notebooks. Here's why it fits TextKit:\n",
        "\n",
        "| Traditional Workflow | nbdev Workflow |\n",
        "|---------------------|----------------|\n",
        "| Write code in `.py` files | Write code in notebooks |\n",
        "| Write separate test files | Tests live next to code |\n",
        "| Write docs separately | Docs generated from notebooks |\n",
        "| Context switching | Single environment |\n",
        "\n",
        "For exploratory, iterative work like text analysis, nbdev keeps everything together.\n",
        "\n",
        "## 1. Setting Up the nbdev Project\n",
        "\n",
        "### Installing nbdev\n",
        "\n",
        "```bash\n",
        "pip install nbdev\n",
        "```\n",
        "\n",
        "### Creating the Project\n",
        "\n",
        "```bash\n",
        "nbdev_new --lib_name textkit --user yourusername --author \"Your Name\"\n",
        "cd textkit\n",
        "```\n",
        "\n",
        "This creates:\n",
        "\n",
        "```\n",
        "textkit/\n",
        "‚îú‚îÄ‚îÄ nbs/                    # Your notebooks live here\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ 00_core.ipynb       # Main module\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ index.ipynb         # Becomes README and docs homepage\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ _quarto.yml         # Documentation config\n",
        "‚îú‚îÄ‚îÄ textkit/                # Generated Python package (don't edit directly)\n",
        "‚îú‚îÄ‚îÄ settings.ini            # Project configuration\n",
        "‚îú‚îÄ‚îÄ setup.py                # Generated for pip install\n",
        "‚îî‚îÄ‚îÄ pyproject.toml\n",
        "```\n",
        "\n",
        "### Key Insight: You Edit Notebooks, Not .py Files\n",
        "\n",
        "The `textkit/` directory contains generated code. Your source of truth is `nbs/*.ipynb`.\n",
        "\n",
        "## 2. Building the Core Module\n",
        "\n",
        "### The First Notebook: `00_core.ipynb`\n",
        "\n",
        "Open `nbs/00_core.ipynb` in Jupyter. The structure:\n",
        "\n",
        "```python\n",
        "# Cell 1: Module header\n",
        "#| default_exp core\n",
        "```\n",
        "\n",
        "This directive tells nbdev: \"export cells from this notebook to `textkit/core.py`\".\n",
        "\n",
        "### Exporting Functions\n",
        "\n",
        "```python\n",
        "#| export\n",
        "def word_count(text: str) -> int:\n",
        "    \"\"\"Count words in text.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        Input text to analyze\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        Number of words\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> word_count(\"Hello world\")\n",
        "    2\n",
        "    >>> word_count(\"\")\n",
        "    0\n",
        "    \"\"\"\n",
        "    if not text or not text.strip():\n",
        "        return 0\n",
        "    return len(text.split())\n",
        "```\n",
        "\n",
        "The `#| export` directive marks this cell for inclusion in the generated module.\n",
        "\n",
        "### Exploring as You Build\n",
        "\n",
        "This is where notebooks shine. Between exported cells, add exploration:\n",
        "\n",
        "```python\n",
        "# Not exported - just exploration\n",
        "sample_text = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "This is a sample paragraph for testing our text analysis functions.\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Word count: {word_count(sample_text)}\")\n",
        "```\n",
        "\n",
        "Your notebook becomes both implementation AND documentation of your thinking.\n",
        "\n",
        "## 3. Adding Tests with nbdev\n",
        "\n",
        "### Inline Doctests\n",
        "\n",
        "The docstring examples above ARE tests. nbdev runs them automatically:\n",
        "\n",
        "```bash\n",
        "nbdev_test\n",
        "```\n",
        "\n",
        "### Dedicated Test Cells\n",
        "\n",
        "For more complex tests:\n",
        "\n",
        "```python\n",
        "#| test\n",
        "def test_word_count_edge_cases():\n",
        "    assert word_count(\"\") == 0\n",
        "    assert word_count(\"   \") == 0\n",
        "    assert word_count(\"one\") == 1\n",
        "    assert word_count(\"one two three\") == 3\n",
        "    # Unicode handling\n",
        "    assert word_count(\"caf√© r√©sum√©\") == 2\n",
        "```\n",
        "\n",
        "### Running Tests\n",
        "\n",
        "```bash\n",
        "# Run all tests\n",
        "nbdev_test\n",
        "\n",
        "# Run tests for specific notebook\n",
        "nbdev_test --path nbs/00_core.ipynb\n",
        "```\n",
        "\n",
        "## 4. Building More Functionality\n",
        "\n",
        "### Readability Scores\n",
        "\n",
        "```python\n",
        "#| export\n",
        "def flesch_reading_ease(text: str) -> float:\n",
        "    \"\"\"Calculate Flesch Reading Ease score.\n",
        "\n",
        "    Scores typically range from 0-100:\n",
        "    - 90-100: Very easy (5th grade)\n",
        "    - 60-70: Standard (8th-9th grade)\n",
        "    - 0-30: Very difficult (college graduate)\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> score = flesch_reading_ease(\"The cat sat on the mat.\")\n",
        "    >>> 90 <= score <= 120  # Simple sentence = high score\n",
        "    True\n",
        "    \"\"\"\n",
        "    words = word_count(text)\n",
        "    sentences = sentence_count(text)\n",
        "    syllables = syllable_count(text)\n",
        "\n",
        "    if words == 0 or sentences == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return (\n",
        "        206.835\n",
        "        - 1.015 * (words / sentences)\n",
        "        - 84.6 * (syllables / words)\n",
        "    )\n",
        "```\n",
        "\n",
        "### Helper Functions\n",
        "\n",
        "```python\n",
        "#| export\n",
        "def sentence_count(text: str) -> int:\n",
        "    \"\"\"Count sentences in text.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> sentence_count(\"Hello. World!\")\n",
        "    2\n",
        "    >>> sentence_count(\"No punctuation here\")\n",
        "    1\n",
        "    \"\"\"\n",
        "    import re\n",
        "    if not text.strip():\n",
        "        return 0\n",
        "    # Split on sentence-ending punctuation\n",
        "    sentences = re.split(r'[.!?]+', text)\n",
        "    # Filter empty strings\n",
        "    return len([s for s in sentences if s.strip()])\n",
        "```\n",
        "\n",
        "```python\n",
        "#| export\n",
        "def syllable_count(text: str) -> int:\n",
        "    \"\"\"Estimate syllable count (English approximation).\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> syllable_count(\"hello\")\n",
        "    2\n",
        "    >>> syllable_count(\"beautiful\")\n",
        "    4\n",
        "    \"\"\"\n",
        "    import re\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "\n",
        "    count = 0\n",
        "    for word in words:\n",
        "        word = re.sub(r'[^a-z]', '', word)\n",
        "        if not word:\n",
        "            continue\n",
        "        # Simple heuristic: count vowel groups\n",
        "        syllables = len(re.findall(r'[aeiouy]+', word))\n",
        "        # Adjust for silent e\n",
        "        if word.endswith('e') and syllables > 1:\n",
        "            syllables -= 1\n",
        "        count += max(1, syllables)\n",
        "\n",
        "    return count\n",
        "```\n",
        "\n",
        "## 5. Visualizations in Your Notebook\n",
        "\n",
        "Notebooks excel at visual exploration. Add analysis cells (not exported):\n",
        "\n",
        "```python\n",
        "# Visualization - not exported, but shows in docs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_readability(texts: dict[str, str]):\n",
        "    \"\"\"Compare readability across multiple texts.\"\"\"\n",
        "    names = list(texts.keys())\n",
        "    scores = [flesch_reading_ease(t) for t in texts.values()]\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.barh(names, scores, color='steelblue')\n",
        "    plt.xlabel('Flesch Reading Ease Score')\n",
        "    plt.title('Readability Comparison')\n",
        "    plt.axvline(x=60, color='red', linestyle='--', label='Standard difficulty')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Demo with sample texts\n",
        "samples = {\n",
        "    \"Children's book\": \"The cat sat. The dog ran. They played.\",\n",
        "    \"News article\": \"The committee announced sweeping regulatory changes affecting multiple industries.\",\n",
        "    \"Academic paper\": \"The epistemological ramifications of quantum indeterminacy necessitate reconceptualization.\",\n",
        "}\n",
        "\n",
        "visualize_readability(samples)\n",
        "```\n",
        "\n",
        "This visualization appears in your generated documentation‚Äîshowing users what the library can do.\n",
        "\n",
        "## 6. Building the Text Analyzer Class\n",
        "\n",
        "For a more complete API, add a class that combines functionality:\n",
        "\n",
        "```python\n",
        "#| export\n",
        "class TextAnalyzer:\n",
        "    \"\"\"Analyze text with multiple metrics.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> analyzer = TextAnalyzer(\"Hello world. How are you?\")\n",
        "    >>> analyzer.word_count\n",
        "    5\n",
        "    >>> analyzer.sentence_count\n",
        "    2\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, text: str):\n",
        "        self.text = text\n",
        "        self._word_count = None\n",
        "        self._sentence_count = None\n",
        "\n",
        "    @property\n",
        "    def word_count(self) -> int:\n",
        "        if self._word_count is None:\n",
        "            self._word_count = word_count(self.text)\n",
        "        return self._word_count\n",
        "\n",
        "    @property\n",
        "    def sentence_count(self) -> int:\n",
        "        if self._sentence_count is None:\n",
        "            self._sentence_count = sentence_count(self.text)\n",
        "        return self._sentence_count\n",
        "\n",
        "    @property\n",
        "    def avg_words_per_sentence(self) -> float:\n",
        "        if self.sentence_count == 0:\n",
        "            return 0.0\n",
        "        return self.word_count / self.sentence_count\n",
        "\n",
        "    @property\n",
        "    def readability(self) -> float:\n",
        "        return flesch_reading_ease(self.text)\n",
        "\n",
        "    def summary(self) -> dict:\n",
        "        \"\"\"Return all metrics as a dictionary.\"\"\"\n",
        "        return {\n",
        "            \"words\": self.word_count,\n",
        "            \"sentences\": self.sentence_count,\n",
        "            \"avg_words_per_sentence\": round(self.avg_words_per_sentence, 1),\n",
        "            \"flesch_reading_ease\": round(self.readability, 1),\n",
        "        }\n",
        "```\n",
        "\n",
        "## 7. Adding an Interactive Widget\n",
        "\n",
        "End with something users can interact with‚Äîdemonstrating the notebook as an application:\n",
        "\n",
        "```python\n",
        "# Interactive demo (not exported - for notebook/docs only)\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def create_analyzer_widget():\n",
        "    \"\"\"Create an interactive text analyzer.\"\"\"\n",
        "\n",
        "    text_input = widgets.Textarea(\n",
        "        value='Enter your text here...',\n",
        "        placeholder='Paste text to analyze',\n",
        "        description='Text:',\n",
        "        layout=widgets.Layout(width='100%', height='150px')\n",
        "    )\n",
        "\n",
        "    output = widgets.Output()\n",
        "\n",
        "    def analyze(change):\n",
        "        output.clear_output()\n",
        "        with output:\n",
        "            if text_input.value.strip():\n",
        "                analyzer = TextAnalyzer(text_input.value)\n",
        "                results = analyzer.summary()\n",
        "                print(\"üìä Analysis Results\")\n",
        "                print(\"-\" * 30)\n",
        "                for key, value in results.items():\n",
        "                    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "    text_input.observe(analyze, names='value')\n",
        "\n",
        "    display(widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üìù Text Analyzer</h3>\"),\n",
        "        text_input,\n",
        "        output\n",
        "    ]))\n",
        "\n",
        "# Show the widget\n",
        "create_analyzer_widget()\n",
        "```\n",
        "\n",
        "When viewed in Colab or Binder, users can interact with your library without installing anything.\n",
        "\n",
        "## 8. Generating the Package\n",
        "\n",
        "### Export to Python Modules\n",
        "\n",
        "```bash\n",
        "nbdev_export\n",
        "```\n",
        "\n",
        "This generates `textkit/core.py` from your notebook's `#| export` cells.\n",
        "\n",
        "### Verify Everything Works\n",
        "\n",
        "```bash\n",
        "# Run tests\n",
        "nbdev_test\n",
        "\n",
        "# Check for issues\n",
        "nbdev_clean\n",
        "nbdev_prepare\n",
        "```\n",
        "\n",
        "### The Generated Code\n",
        "\n",
        "Look at `textkit/core.py`‚Äîit contains clean Python code generated from your notebooks, with proper imports and structure.\n",
        "\n",
        "## 9. Documentation\n",
        "\n",
        "### The Index Notebook\n",
        "\n",
        "`nbs/index.ipynb` becomes both your README.md and documentation homepage. Include:\n",
        "\n",
        "1. Installation instructions\n",
        "2. Quick start example\n",
        "3. Feature overview\n",
        "\n",
        "```python\n",
        "# In nbs/index.ipynb\n",
        "\n",
        "# TextKit\n",
        "\n",
        "> Simple text analysis for Python\n",
        "\n",
        "## Installation\n",
        "\n",
        "```bash\n",
        "pip install textkit\n",
        "```\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "```python\n",
        "from textkit.core import TextAnalyzer\n",
        "\n",
        "text = \"Your text here. Analyze it easily.\"\n",
        "analyzer = TextAnalyzer(text)\n",
        "print(analyzer.summary())\n",
        "```\n",
        "```\n",
        "\n",
        "### Build Documentation\n",
        "\n",
        "```bash\n",
        "nbdev_docs\n",
        "```\n",
        "\n",
        "This generates a Quarto-based documentation site in `_docs/`.\n",
        "\n",
        "## 10. Publishing to PyPI\n",
        "\n",
        "### Prepare for Release\n",
        "\n",
        "```bash\n",
        "# Clean and prepare\n",
        "nbdev_prepare\n",
        "\n",
        "# Build distribution\n",
        "python -m build\n",
        "```\n",
        "\n",
        "### Publish\n",
        "\n",
        "```bash\n",
        "# Test PyPI first\n",
        "twine upload --repository testpypi dist/*\n",
        "\n",
        "# Then real PyPI\n",
        "twine upload dist/*\n",
        "```\n",
        "\n",
        "### The Result\n",
        "\n",
        "```bash\n",
        "pip install textkit\n",
        "```\n",
        "\n",
        "You've shipped a Python package‚Äîdeveloped entirely in notebooks.\n",
        "\n",
        "## 11. Sharing the Notebook Itself\n",
        "\n",
        "Beyond the package, share the development notebook:\n",
        "\n",
        "### Colab Badge\n",
        "\n",
        "```markdown\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/username/textkit/blob/main/nbs/00_core.ipynb)\n",
        "```\n",
        "\n",
        "### Binder Badge\n",
        "\n",
        "```markdown\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/username/textkit/main)\n",
        "```\n",
        "\n",
        "Users can:\n",
        "1. **Install the package** via pip (traditional)\n",
        "2. **Explore the notebook** to understand the code (educational)\n",
        "3. **Run interactively** in Colab/Binder (zero-install)\n",
        "\n",
        "## Comparing Workflows\n",
        "\n",
        "Here's how this case study compares to the SimpleBot approach (@sec-case-study):\n",
        "\n",
        "| Aspect | SimpleBot (Scripts) | TextKit (nbdev) |\n",
        "|--------|---------------------|-----------------|\n",
        "| Source files | `.py` in `src/` | `.ipynb` in `nbs/` |\n",
        "| Tests | Separate `tests/` directory | Inline with code |\n",
        "| Documentation | Separate `docs/` | Generated from notebooks |\n",
        "| Exploration | Separate REPL/scratch files | Integrated in notebooks |\n",
        "| Output | Package on PyPI | Package on PyPI |\n",
        "| Best for | Traditional dev, teams | Exploratory, teaching |\n",
        "\n",
        "Both workflows produce the same result: a published package. Choose based on how you like to work.\n",
        "\n",
        "## When to Use This Workflow\n",
        "\n",
        "The nbdev approach works best when:\n",
        "\n",
        "- **Exploration is central**: You're figuring things out as you build\n",
        "- **Teaching matters**: Others will learn from your notebooks\n",
        "- **Docs should show execution**: You want live examples in documentation\n",
        "- **Solo or small team**: Git conflicts in notebooks are real\n",
        "\n",
        "Consider traditional scripts when:\n",
        "\n",
        "- **Large teams**: Notebook diffs are harder to review\n",
        "- **Complex architecture**: Many interconnected modules\n",
        "- **Heavy IDE reliance**: Refactoring tools work better with `.py` files\n",
        "- **Existing codebase**: Converting to nbdev is non-trivial\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **nbdev inverts the workflow**: Notebooks are source, `.py` files are generated\n",
        "- **Tests live with code**: Doctests and `#| test` cells eliminate context switching\n",
        "- **Exploration becomes documentation**: Your investigative work helps users\n",
        "- **Same destination**: Published package, installable via pip\n",
        "- **Different journey**: Iterative, visual, integrated\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. **Extend TextKit**: Add a `sentiment_words()` function that counts positive/negative words from a simple word list. Include doctests.\n",
        "\n",
        "2. **Add a notebook**: Create `01_advanced.ipynb` with functions for text comparison (e.g., similarity between two texts).\n",
        "\n",
        "3. **Publish to TestPyPI**: Go through the full publication workflow to TestPyPI.\n",
        "\n",
        "4. **Create a Voil√† dashboard**: Convert the interactive widget section into a standalone Voil√† dashboard.\n",
        "\n",
        "5. **Compare workflows**: Take one function from TextKit and rewrite it in the traditional script workflow. Reflect on the differences."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/michael/Library/Application Support/uv/envs/general/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}